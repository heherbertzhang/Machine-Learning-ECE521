{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def euclidean_dist(x, z):\n",
    "  n2 = tf.shape(z)[0]\n",
    "  x_ = tf.expand_dims(x,len(x.shape))\n",
    "  # x_ = tf.tile(x_, [1,1, n2]) #optional, will be broadcasted\n",
    "  z_ = tf.expand_dims(tf.transpose(z),0)\n",
    "  res = tf.square(x_- z_)\n",
    "  res = tf.reduce_sum(res, 1)\n",
    "  return res\n",
    "\n",
    "import numpy as np\n",
    "def split_data():\n",
    "  np.random.seed(521)\n",
    "  Data = np.linspace(1.0, 10.0, num=100)[:, np.newaxis]\n",
    "  Target = np.sin(Data) + 0.1*np.power(Data,2) + 0.5*np.random.randn(100,1)\n",
    "  randIdx = np.arange(100)\n",
    "  np.random.shuffle(randIdx)\n",
    "  trainData, trainTarget = Data[randIdx[:80]], Target[randIdx[:80]]\n",
    "  validData, validTarget = Data[randIdx[80:90]], Target[randIdx[80:90]]\n",
    "  testData, testTarget = Data[randIdx[90:100]], Target[randIdx[90:100]]\n",
    "  return trainData, trainTarget, validData, validTarget, testData, testTarget\n",
    "\n",
    "def data_segmentation(data_path, target_path, task):\n",
    "  # task = 0 >> select the name ID targets for face recognition task\n",
    "  # task = 1 >> select the gender ID targets for gender recognition task\n",
    "  data = np.load(data_path)/255\n",
    "  data = np.reshape(data, [-1, 32*32])\n",
    "  target = np.load(target_path)\n",
    "  np.random.seed(45689)\n",
    "  rnd_idx = np.arange(np.shape(data)[0])\n",
    "  np.random.shuffle(rnd_idx)\n",
    "  trBatch = int(0.8*len(rnd_idx))\n",
    "  validBatch = int(0.1*len(rnd_idx))\n",
    "  trainData, validData, testData = data[rnd_idx[1:trBatch],:], \\\n",
    "  data[rnd_idx[trBatch+1:trBatch + validBatch],:],\\\n",
    "  data[rnd_idx[trBatch + validBatch+1:-1],:]\n",
    "  trainTarget, validTarget, testTarget = target[rnd_idx[1:trBatch], task], \\\n",
    "  target[rnd_idx[trBatch+1:trBatch + validBatch], task],\\\n",
    "  target[rnd_idx[trBatch + validBatch + 1:-1], task]\n",
    "  return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
    "\n",
    "class KNNBuilder:\n",
    "  def __init__(self, k):\n",
    "    self.k = k\n",
    "  def setData(self, trainData, trainTarget, validData, validTarget, testData, testTarget):\n",
    "    self.trainData = trainData\n",
    "    self.trainTarget = trainTarget\n",
    "    self.validData = validData\n",
    "    self.validTarget = validTarget\n",
    "    self.testData = testData\n",
    "    self.testTarget = testTarget\n",
    "  def build(self):\n",
    "    trainData = tf.placeholder(tf.float32, shape=(None, 1), name=\"trainData\")\n",
    "    trainTarget = tf.placeholder(tf.float32, shape=(None, 1), name=\"trainTarget\")\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None,1), name=\"X\")\n",
    "    distances = -euclidean_dist(X,trainData)\n",
    "    k_neighbors, k_indices = tf.nn.top_k(distances, k=self.k, name=\"k_neighbors\") # size is n*k\n",
    "\n",
    "    k_indices = tf.expand_dims(k_indices, 2)\n",
    "    predictions = tf.gather_nd(trainTarget,k_indices)\n",
    "    predictions = tf.reduce_mean(predictions, 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, validData, testData, trainTarget, validTarget, testTarget = data_segmentation('data.npy', 'target.npy', 1)\n",
    "data = [trainData, trainTarget, validData, validTarget, testData, testTarget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78431373,  0.77254902,  0.52156863, ...,  0.29803922,\n",
       "         0.10196078,  0.08627451],\n",
       "       [ 0.16078431,  0.1372549 ,  0.15294118, ...,  0.2745098 ,\n",
       "         0.30980392,  0.34509804],\n",
       "       [ 0.29803922,  0.32156863,  0.27058824, ...,  0.04705882,\n",
       "         0.07058824,  0.05098039],\n",
       "       ..., \n",
       "       [ 0.79607843,  0.4745098 ,  0.37254902, ...,  0.10980392,\n",
       "         0.10980392,  0.13333333],\n",
       "       [ 0.13333333,  0.10588235,  0.30980392, ...,  0.55686275,\n",
       "         0.83137255,  0.95686275],\n",
       "       [ 0.15294118,  0.14117647,  0.22352941, ...,  0.93333333,\n",
       "         0.85882353,  0.69411765]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_classifer_builder:\n",
    "  def __init__(self, k):\n",
    "    self.k = k\n",
    "  def setData(self, trainData, trainTarget, validData, validTarget, testData, testTarget):\n",
    "    self.trainData = trainData\n",
    "    self.trainTarget = trainTarget\n",
    "    self.validData = validData\n",
    "    self.validTarget = validTarget\n",
    "    self.testData = testData\n",
    "    self.testTarget = testTarget\n",
    "  def build(self):\n",
    "    tf.reset_default_graph()\n",
    "    trainData = tf.placeholder(tf.float32, shape=(None, 1024), name=\"trainData\") #n2*1\n",
    "    trainTarget = tf.placeholder(tf.int32, shape=(None, 1), name=\"trainTarget\")\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 1024), name=\"X\")\n",
    "    \n",
    "    distances = -euclidean_dist(X,trainData) #n1*n2\n",
    "    k_neighbors, k_indices = tf.nn.top_k(distances, k=self.k, name=\"k_neighbors\") # size is n1*k, choose k indice from n2\n",
    "\n",
    "    k_indices = tf.expand_dims(k_indices, 2) #traintarget is 2d, so the indice should be 2d, expand k so that each indice is 2d\n",
    "    predictions = tf.gather_nd(trainTarget,k_indices)\n",
    "    predictions = tf.squeeze(predictions, 2)\n",
    "    #n1 = tf.shape(predictions,out_type=tf.int32)[0]\n",
    "    #i = tf.constant(0,dtype=tf.int32)\n",
    "    #cond = lambda i: tf.less(i, 10)\n",
    "    #tmp_res = tf.Variable(tf.constant(0,shape=[92,1]))\n",
    "    #body = lambda i: tf.add(i, 1)\n",
    "    #def cond(i,n1,tmp_res):\n",
    "     #   return tf.less(i,n1)\n",
    "    #def body(i,n1,tmp_res):\n",
    "     #   uniques,idxs,counts = tf.unique_with_counts(predictions[i])\n",
    "      #  #tmp_res.append(tf.cast(uniques[tf.cast(tf.argmax(counts),tf.int32)], tf.int32))\n",
    "       # tmp_res[i] = tf.cast(uniques[tf.cast(tf.argmax(counts),tf.int32)], tf.int32)\n",
    "        #return tf.add(i,1), n1, tmp_res\n",
    "    #loop_res=tf.while_loop(cond,body,[i,n1,tmp_res])\n",
    "    self.all_predictions = predictions\n",
    "    return predictions\n",
    "    #tf.unique_with_counts(predictions)\n",
    "  def run(self, sess):\n",
    "    feed_dict={tf.get_default_graph().get_tensor_by_name('trainData:0'):self.trainData, \\\n",
    "                        tf.get_default_graph().get_tensor_by_name('trainTarget:0'):self.trainTarget[:,np.newaxis], \\\n",
    "                        tf.get_default_graph().get_tensor_by_name('X:0'):self.validData}\n",
    "\n",
    "    res = []\n",
    "    for i in range(self.validData.shape[0]):\n",
    "        get_counts_i = tf.unique_with_counts(self.all_predictions[i])\n",
    "        uniques, indices, counts = get_counts_i\n",
    "        max_i = tf.cast(tf.argmax(counts),tf.int32)\n",
    "        tmp = uniques[max_i]\n",
    "        res.append(tmp)\n",
    "    return sess.run(res, feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_c = KNN_classifer_builder(5)\n",
    "knn_c.build()\n",
    "knn_c.setData(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sess2 = tf.Session()\n",
    "#print(sess2.run(knn_c, feed_dict={'trainData:0':trainData, 'trainTarget:0':trainTarget[:,np.newaxis], 'X:0':validData}))\n",
    "print(knn_c.run(sess2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0 1 2 0] [2 1 1]\n"
     ]
    }
   ],
   "source": [
    "get_counts_i = tf.unique_with_counts([1,2,3, 1])\n",
    "uniques, indices, counts = sess2.run(get_counts_i)\n",
    "print (uniques, indices, counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
